\documentclass[11pt,a4paper,oneside]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{color}
\usepackage {tikz}
\usetikzlibrary {er}
\usepackage[left=2.00cm, right=2.00cm, top=1.00cm]{geometry}
\graphicspath{{./}}

\begin{document}
	\title{DS 221 - Introduction to Scalable Systems \\ Assignment 1}
	\author{Shriram R. \\ M Tech (CDS) \\ 06-02-01-10-51-18-1-15763}
	\maketitle
	
	\section{2D Matrices}
	The 2D matrix abstract data structure has been implemented using 2D array and compressed sparse matrix representation (CSR) and the space and time complexities has been analyzed and empirically verified.
	The following sections will cover the analysis and empirical results in detail.
	
	\subsection{Storage Space}
	It is assumed that the $N$, $M$ and $NNZ$ are the number of rows, columns and non-zero elements of the matrix respectively. For 2D array implementation, space is allocated to each element irrespective of the value and so the asymptotic space complexity is $O(NM)$. Whereas, for CSR implementation, we have three arrays A, IA and JA each having $NNZ$, $M+1$ and $NNZ$ elements respectively. Hence, the asymptotic space complexity is $O(M+NNZ)$ 

    \subsection{Matrix Addition}
    For matrix addition, all the elements of the input and output matrices have to be processed exactly once and there are $MN$ elements. In the case of 2D matrix implementation, each element can be accessed in $O(1)$ time and so the total time complexity for addition in this case is $O(MN)$. For the case of CSR implementation, each element can accessed in $O(N)$ time assuming the worst case where a row has all the elements as non-zero. So, the time complexity for addition in this case will be $O(MN^2)$.
    
    \subsection{Matrix Multiplication}
    
    
	\begin{center}
	\begin{tabular}{|l|l|l|l|}
		\hline
		Program & 512 & 1024 &  2048\\
		\hline
		Cache + Vec & 0.046s & 0.513s & 4.803s \\
		Cache & 0.447s & 3.595s & 29.292s \\
		Naive + Vec & 0.123s & 2.967s & 44.943s \\
		Naive & 0.798s & 16.532s & 179.477s \\				
		\hline
	\end{tabular}
	\end{center}

     \begin{verbatim}
    
    \end{verbatim}

    \section{Conclusion}
    It has been observed that the cache optimized and vectorized version of the program performs significantly better and scales well with the size of matrix. The optimized version took $0.513s$ to multiply 1024x1024 matrices of \emph{double} items. It is possible to improve the performance further by using divide and conquer algorithm like Strassen's which has a better complexity than $O(n^3)$. 
    
    \section{References}
    
    \begin{list}{*}{}
    	\item https://gcc.gnu.org/projects/tree-ssa/vectorization.html
    	\item https://stackoverflow.com/questions/1847789/segmentation-fault-on-large-array-sizes
    	\item https://linux.die.net/man/3/clock\_gettime
    	\item DS 221 Course lecture notes
    \end{list}

\end{document}